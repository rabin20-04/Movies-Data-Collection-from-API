{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3278703c-8e3e-48e7-8d9e-ec9d9a3441a2",
   "metadata": {},
   "source": [
    "## Table \n",
    "# Web scarping\n",
    "sn | content \n",
    "---|-------\n",
    "1 | Header\n",
    "2) | Part 1\n",
    "3 | Find the all tags from HTML\n",
    "4 | For multiple tags\n",
    "5 |tag with some class only \n",
    "6 |Actual method to extract data \n",
    "7 |\n",
    "8 |\n",
    "9 |\n",
    "10 |\n",
    "11 |\n",
    "12 |\n",
    "13 |\n",
    "14 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6747b80-8688-4110-bb2a-4be0a5f369ec",
   "metadata": {},
   "source": [
    "# 1. BeautifulSoup is a python library for web scarping  very useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52f6f52-8067-44d3-af73-6ef125fbea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as Bs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65341806-6cfb-43a1-a5ac-e5064a727f19",
   "metadata": {},
   "source": [
    "### if done directly then it avoids request  \n",
    "- requests.get(\"https://www.ambitionbox.com/list-of-companies?page=1\")\n",
    "- these website assumes us as bot if we try to web scarp directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb341f-88fd-4ec9-b2fd-6abceb05d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(\"https://www.ambitionbox.com/list-of-companies?page=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2216e-fcbc-4e73-8226-87985ed96448",
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get(\"https://www.ambitionbox.com/list-of-companies?page=1\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e69e5-14e0-4ec8-85be-216b26adaaed",
   "metadata": {},
   "source": [
    "# 1) Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a63e5-7548-4d64-8f97-2321a61e7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.162 Safari/537.36'\n",
    "}\n",
    "\n",
    "web_page=requests.get(\"https://www.ambitionbox.com/list-of-companies?page=1\",headers=headers).text\n",
    "web_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c73567e-d05d-4d63-87b1-5c2e4ad827f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=Bs(web_page,\"lxml\") # lxml is a used to parse html like it makes the code appear like inspect windows code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ea450-48ef-405e-90a1-90d8d649dde5",
   "metadata": {},
   "source": [
    "print(soup.prettify())   #this will display the html code as it seems in source code or normal html file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a6a7f-3198-4e6c-a70a-ac0b9c79a04b",
   "metadata": {},
   "source": [
    "# 2) PART 1  \n",
    "-- UPTO HERE THIS  part covers \n",
    "- taking html code from website\n",
    "- and making the html code in formatted way\n",
    "- to understand what the html contains and\n",
    "- what we need  from that HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd932caa-cf36-46dd-8b65-933994d89597",
   "metadata": {},
   "source": [
    "# 3) To find any tags in the entire HTML\n",
    "```python \n",
    "soup.find_all(\"h1\") # it will print all the h1 tags from the file in list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45af240-5bcd-4176-af51-18ea979ff412",
   "metadata": {},
   "source": [
    "- soup.find_all(\"h1\") returns whole h1 code to only extract text from that tag "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee75e1c-a9e5-4906-b4cb-eee80a3d5c5b",
   "metadata": {},
   "source": [
    "- soup.find_all(\"h2\")[0].text\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d336731-7efa-462d-86a7-863e12cf1445",
   "metadata": {},
   "source": [
    "# 4) For multiple tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc3cbc-9e56-4b24-8e27-465a82a8723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all(\"h1\"):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38e08c4-0aa2-406d-8e1c-29622101f0d7",
   "metadata": {},
   "source": [
    "- ## by default some formatting is done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c0d0d3-a9aa-4672-8505-ea5b1edb1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in soup.find_all(\"h1\"):\n",
    "    print(i.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182b67d-d67d-4888-a5b7-b8d29170d07a",
   "metadata": {},
   "source": [
    "# 5) tag with some class only "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9232aeb8-1297-4957-9f82-1261a616ca2e",
   "metadata": {},
   "source": [
    "```python\n",
    "soup.find_all(\"h1\",class=\"rating\") # find all with h1 tags but with class rating\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d45a74-abe8-447c-a379-14ce2f601a43",
   "metadata": {},
   "source": [
    "# 6) Actual method to extract data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e56d11-fe23-4366-97b8-cc3b6add8112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # company wrapper is the div which contains the details of the company in that website \n",
    "name=[]                                       \n",
    "rating=[]                                                          #text strip to remove the default formatting \n",
    "for i in soup.find_all(\"div\",class=\"company-wrapper\"):             #find all means multiple find means single use any\n",
    "   name.apped(i.find(\"h2\").text_strip())                           #find because there is only one title \n",
    "    # here i is every div as companies are in the divs of same class container \n",
    "    # i is one of company div from the list of divs generated from soup.find_all(\"div\",class=\"company-wrapper\")\n",
    "   rating.append(i.find(\"p\",class=\"rating\").text_strip))             #find_all because there are multiple p  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603a8fd-55b3-487b-80d0-916cc2ee6009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20adde8-3bea-4525-bc3d-cf41c7e4057f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
